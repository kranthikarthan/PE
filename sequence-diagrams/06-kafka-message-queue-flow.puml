@startuml KAFKA_MESSAGE_QUEUE_FLOW
!theme plain
title Kafka Message Queue & Event Streaming Flow

actor Client as C
participant "API Gateway" as AG
participant "Payment Processing Service" as MS
participant "Kafka Producer" as KP
participant "Kafka Broker" as KB
participant "Kafka Consumer" as KC
participant "Dead Letter Queue" as DLQ
participant "Webhook Service" as WS
participant "Monitoring" as M

== Asynchronous Message Processing Flow ==

C -> AG: POST /api/v1/iso20022/comprehensive/pain001
note right: Response Mode: ASYNC\nCorrelation ID: <correlation-id>

AG -> AG: Validate Request
AG -> MS: Forward Request
MS -> MS: Process PAIN.001 Message
MS -> MS: Transform to PACS.008
MS -> CS: Send to Clearing System
CS --> MS: Return PACS.002 Response
MS -> MS: Transform to PAIN.002

== Kafka Message Production ==

MS -> KP: Send Message to Kafka
note right: Topic: tenant-<tenant-id>\nKey: <correlation-id>\nMessage: PAIN.002\nHeaders: {messageType: pain002, tenantId: <tenant-id>, correlationId: <correlation-id>}

KP -> KP: Serialize Message
note right: Serializer: JsonSerializer\nKey Serializer: StringSerializer\nCompression: snappy

KP -> KB: Produce Message
note right: Partition: <partition-id>\nOffset: <offset>\nTimestamp: <timestamp>\nAcks: all

KB -> KB: Store Message
note right: Replication: 3\nDurability: High\nRetention: 7 days

KB --> KP: Return Acknowledgment
note right: Partition: <partition-id>\nOffset: <offset>\nTimestamp: <timestamp>

KP -> M: Record Producer Metrics
note right: Metrics:\n- kafka_producer_messages_sent_total: +1\n- kafka_producer_bytes_sent_total: +<message-size>\n- kafka_producer_latency_seconds: <latency>

KP --> MS: Return Success
MS --> AG: Return 202 Accepted
AG --> C: Return 202 Accepted
note right: Status: 202 Accepted\nMessage: "Payment processing initiated"\nCorrelation ID: <correlation-id>

== Kafka Message Consumption ==

KC -> KB: Poll for Messages
note right: Topic: tenant-<tenant-id>\nGroup ID: iso20022-consumer-group\nMax Poll Records: 10\nAuto Offset Reset: earliest

KB --> KC: Return Message Batch
note right: Messages: [PAIN.002, PACS.004, CAMT.054]\nPartitions: [0, 1, 2]\nOffsets: [100, 101, 102]

KC -> KC: Deserialize Messages
note right: Deserializer: JsonDeserializer\nKey Deserializer: StringDeserializer\nTrusted Packages: com.paymentengine.*

KC -> KC: Process Each Message
note right: Message 1: PAIN.002\nMessage 2: PACS.004\nMessage 3: CAMT.054

== Message Processing Success ==

KC -> KC: Process PAIN.002 Message
note right: Message Type: PAIN.002\nTenant ID: <tenant-id>\nCorrelation ID: <correlation-id>

KC -> WS: Deliver Webhook
note right: Webhook URL: <client-webhook>\nMessage: PAIN.002\nRetry: 3 attempts\nTimeout: 10s

WS -> C: POST Webhook
note right: URL: <client-webhook>\nHeaders: {X-Signature: <signature>, X-Correlation-ID: <correlation-id>}\nBody: PAIN.002 message

alt Webhook Delivery Successful
    C --> WS: Return 200 OK
    WS --> KC: Return Success
    KC -> KC: Commit Offset
    note right: Partition: 0\nOffset: 100\nCommitted: true
    
    KC -> M: Record Consumer Metrics
    note right: Metrics:\n- kafka_consumer_messages_processed_total: +1\n- kafka_consumer_processing_duration_seconds: <duration>\n- webhook_delivery_success_total: +1
    
else Webhook Delivery Failed
    C --> WS: Return 500 Internal Server Error
    WS -> WS: Apply Retry Logic
    note right: Attempt: 1/3\nWait Time: 1s\nNext Attempt: 2
    
    WS -> C: Retry Webhook Delivery
    C --> WS: Return 500 Internal Server Error
    WS -> WS: Apply Retry Logic
    note right: Attempt: 2/3\nWait Time: 2s\nNext Attempt: 3
    
    WS -> C: Retry Webhook Delivery
    C --> WS: Return 500 Internal Server Error
    WS -> WS: All Retries Exhausted
    note right: Attempt: 3/3\nStatus: Failed\nAction: Send to DLQ
    
    WS -> DLQ: Send Failed Message
    note right: Topic: failed-webhooks.dlq\nKey: <correlation-id>\nMessage: PAIN.002\nError: Webhook delivery failed\nRetry Count: 3
    
    KC -> KC: Commit Offset (Failed Message)
    KC -> M: Record Consumer Metrics
    note right: Metrics:\n- kafka_consumer_messages_processed_total: +1\n- webhook_delivery_failure_total: +1\n- dead_letter_queue_messages_total: +1
end

== Dead Letter Queue Processing ==

DLQ -> DLQ: Store Failed Message
note right: Topic: failed-webhooks.dlq\nPartition: 0\nOffset: <dlq-offset>\nRetention: 30 days

DLQ -> M: Record DLQ Metrics
note right: Metrics:\n- dead_letter_queue_messages_total: +1\n- dead_letter_queue_size: +1\n- dead_letter_queue_oldest_message_age_seconds: <age>

== Message Processing Error ==

KC -> KC: Process PACS.004 Message
note right: Message Type: PACS.004\nTenant ID: <tenant-id>\nCorrelation ID: <correlation-id>

KC -> KC: Validate Message
note right: Validation: Schema validation\nStatus: Failed\nError: Invalid message format

KC -> KC: Handle Processing Error
note right: Error Handler: KafkaErrorHandler\nAction: Send to DLQ\nReason: Processing failed

KC -> DLQ: Send Failed Message
note right: Topic: failed-messages.dlq\nKey: <correlation-id>\nMessage: PACS.004\nError: Invalid message format\nOriginal Topic: tenant-<tenant-id>

KC -> KC: Commit Offset (Failed Message)
KC -> M: Record Consumer Metrics
note right: Metrics:\n- kafka_consumer_messages_processed_total: +1\n- kafka_consumer_processing_errors_total: +1\n- dead_letter_queue_messages_total: +1

== Kafka Topic Management ==

== Topic Creation ==

MS -> KB: Create Tenant Topic
note right: Topic: tenant-<tenant-id>\nPartitions: 3\nReplication Factor: 3\nRetention: 7 days

KB -> KB: Create Topic
note right: Topic: tenant-<tenant-id>\nPartitions: [0, 1, 2]\nReplicas: [broker-1, broker-2, broker-3]\nStatus: Created

KB --> MS: Return Topic Creation Success
MS -> M: Record Topic Metrics
note right: Metrics:\n- kafka_topics_total: +1\n- kafka_partitions_total: +3\n- kafka_replicas_total: +9

== Topic Configuration ==

MS -> KB: Configure Topic
note right: Topic: tenant-<tenant-id>\nConfig: {retention.ms: 604800000, segment.ms: 86400000, compression.type: snappy}

KB -> KB: Update Topic Configuration
note right: Topic: tenant-<tenant-id>\nNew Config: Applied\nStatus: Updated

KB --> MS: Return Configuration Success
MS -> M: Record Configuration Metrics
note right: Metrics:\n- kafka_topic_config_updates_total: +1\n- kafka_topic_retention_seconds: 604800

== Consumer Group Management ==

KC -> KB: Join Consumer Group
note right: Group ID: iso20022-consumer-group\nMember ID: consumer-1\nTopics: [tenant-*, system-*]

KB -> KB: Register Consumer
note right: Group: iso20022-consumer-group\nMembers: [consumer-1, consumer-2, consumer-3]\nPartitions: Assigned

KB --> KC: Return Partition Assignment
note right: Partitions: [0, 1]\nTopics: [tenant-tenant1, tenant-tenant2]\nAssignment: Balanced

KC -> M: Record Consumer Group Metrics
note right: Metrics:\n- kafka_consumer_group_members: 3\n- kafka_consumer_group_partitions: 6\n- kafka_consumer_group_lag: 0

== Kafka Monitoring & Health Checks ==

M -> KB: Check Kafka Health
note right: Health Checks:\n- Broker connectivity\n- Topic availability\n- Partition leadership\n- Replication status

KB --> M: Return Health Status
note right: Status: HEALTHY\nBrokers: 3/3\nTopics: 15/15\nPartitions: 45/45\nReplicas: 135/135

M -> M: Update Kafka Metrics
note right: Metrics:\n- kafka_brokers_total: 3\n- kafka_topics_total: 15\n- kafka_partitions_total: 45\n- kafka_replicas_total: 135\n- kafka_health_status: 1

== Message Replay & Recovery ==

DLQ -> DLQ: Process DLQ Messages
note right: Topic: failed-webhooks.dlq\nMessages: 5\nAction: Replay to original topic

DLQ -> KB: Replay Messages
note right: From Topic: failed-webhooks.dlq\nTo Topic: tenant-<tenant-id>\nMessages: 5\nOffset: Reset to beginning

KB -> KB: Replay Messages
note right: Topic: tenant-<tenant-id>\nPartitions: [0, 1, 2]\nMessages: 5\nStatus: Replayed

KB --> DLQ: Return Replay Success
DLQ -> M: Record Replay Metrics
note right: Metrics:\n- kafka_message_replay_total: +5\n- dead_letter_queue_messages_processed_total: +5\n- dead_letter_queue_size: -5

== Kafka Security & Authentication ==

KP -> KB: Authenticate Producer
note right: Authentication: SASL/SCRAM-SHA-256\nUsername: <producer-user>\nPassword: <producer-password>

KB -> KB: Validate Credentials
note right: User: <producer-user>\nPermissions: [produce, describe]\nTopics: [tenant-*, system-*]

KB --> KP: Return Authentication Success
KP -> KB: Produce Message with ACL
note right: Topic: tenant-<tenant-id>\nACL: Allow\nUser: <producer-user>\nOperation: Write

KC -> KB: Authenticate Consumer
note right: Authentication: SASL/SCRAM-SHA-256\nUsername: <consumer-user>\nPassword: <consumer-password>

KB -> KB: Validate Credentials
note right: User: <consumer-user>\nPermissions: [consume, describe]\nTopics: [tenant-*, system-*]

KB --> KC: Return Authentication Success
KC -> KB: Consume Message with ACL
note right: Topic: tenant-<tenant-id>\nACL: Allow\nUser: <consumer-user>\nOperation: Read

== Kafka Features Summary ==

note over C,M
Kafka Features Implemented:
- Message Production with Compression
- Message Consumption with Deserialization
- Dead Letter Queue for Failed Messages
- Webhook Delivery with Retry Logic
- Topic Management & Configuration
- Consumer Group Management
- Partition Assignment & Rebalancing
- Message Replay & Recovery
- Security & Authentication (SASL/SCRAM)
- Access Control Lists (ACL)
- Monitoring & Health Checks
- Metrics Collection & Export
- Error Handling & Recovery
- Message Retention & Cleanup
- Replication & Durability
- High Availability & Fault Tolerance
- Performance Optimization
- Schema Registry Integration
- Event Sourcing Support
- Stream Processing Capabilities
end note

@enduml